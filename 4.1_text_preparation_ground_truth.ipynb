{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1\tAnalyse des Goldstandard-Korpus\n",
    "## Text Vorbereitung für die Analyse mit N-Grams und Voyant Tools\n",
    "\n",
    "\n",
    "### Herangehensweise:\n",
    "\n",
    "Die Inhalte der Stellenanzeigen soll in anderen Notebooks näher untersucht werden. Dazu wird der Text weiter normalisiert und von Stopwörtern befreit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_punctuation(df, column_inputText, newColumnName):\n",
    "    \"\"\"\n",
    "    Needs a datframe with a text (string) column\n",
    "    1. creates a new column\n",
    "    2. erases all puntuation in this new column\n",
    "    3. return df\n",
    "    \"\"\"\n",
    "    df[newColumnName] = df[column_inputText].str.replace('[^\\w\\s]','')\n",
    "    return df\n",
    "\n",
    "def tokenize(df, column_inputText, newColumnName):\n",
    "    \"\"\"\n",
    "    Needs the following import:\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    Needs a datframe with a text (string) column\n",
    "    1. creates a new column\n",
    "    2. tokenizes the text in the new column\n",
    "    3. return df\n",
    "    \"\"\"\n",
    "    df[newColumnName] = df[column_inputText].apply(word_tokenize)\n",
    "    return df\n",
    "\n",
    "def detokenize(df, column_inputText, newColumnName):\n",
    "    \"\"\"\n",
    "    Needs a dataframe with a tokenized text column (column_inputText)\n",
    "    1. creates a new column\n",
    "    2. joins Text in List format to string\n",
    "    3. return df\n",
    "    \"\"\"\n",
    "    df[newColumnName] = [' '.join(map(str, l)) for l in df[column_inputText]]\n",
    "    return df\n",
    "\n",
    "def no_stopwords(df, column_inputText, newColumnName):\n",
    "    \"\"\"\n",
    "    Needs the following import:\n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    Needs a dataframe with tokenized text (list) column and list with stopwords named \"stopwords\"\n",
    "    1. creates a new column\n",
    "    2. reases all the stopwords from the new text column\n",
    "    3. return df\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords)\n",
    "    df[newColumnName] = df[column_inputText].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    return df\n",
    "\n",
    "def plot_top_stopwords_barchart(text):\n",
    "    \"\"\"\n",
    "    Needs the following import:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    Needs a datframe with text column\n",
    "    1. finds all the stopwords in the text\n",
    "    2. plots the stopwords to be deleted in a bar chart\n",
    "    \"\"\"\n",
    "    stop = set(stopwords)\n",
    "    \n",
    "    new = text.str.split()\n",
    "    new = new.values.tolist()\n",
    "    corpus = [word for i in new for word in i]\n",
    "    from collections import defaultdict\n",
    "    dic = defaultdict(int)\n",
    "    for word in corpus:\n",
    "        if word in stop:\n",
    "            dic[word]+=1\n",
    "            \n",
    "    top = sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]\n",
    "    x,y = zip(*top)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.bar(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datenimport\n",
    "#### Import des Dataframe df_master file von 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/3.3_ocr_ground_truth_vergleich/difference_output_normalized_corpus.csv\")\n",
    "df = df[[\"identifier\", \"region_class\", \"pub_id\", \"pub_name\", \"date\", \"ground_truth_normalized\", \"OCR_normalized\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Stopword Liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/stopwords.txt') as f:\n",
    "        stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anwendung der Funktionen zur Erstellung des Master Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die einheitliche Bennennung der neuen Spalten des Dataframes muss der Beginn der neuen Spaltennamen definiert werden.\n",
    "Da es sich hier um die Verarbeitung des Goldstandard Korpus handelt, wurde dafür 'ground_truth' gewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnname = \"ground_truth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Datenreinigung\n",
    "\n",
    "- columnname_nP\n",
    "- columnname_Tokens\n",
    "- columnname_nSW_Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/x4qm1hmx4sj6q61rdmcwx57m0000gn/T/ipykernel_5138/3317487459.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[newColumnName] = df[column_inputText].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "df = erase_punctuation(df, \"ground_truth_normalized\", columnname+\"_nP\")\n",
    "df = tokenize(df, columnname+\"_nP\", columnname+\"_Tokens\")\n",
    "df = no_stopwords(df, columnname+\"_Tokens\", columnname+\"_nSW_Tokens\")\n",
    "df = detokenize(df, columnname+\"_nSW_Tokens\", columnname+\"_nSW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>region_class</th>\n",
       "      <th>pub_id</th>\n",
       "      <th>pub_name</th>\n",
       "      <th>date</th>\n",
       "      <th>ground_truth_normalized</th>\n",
       "      <th>OCR_normalized</th>\n",
       "      <th>ground_truth_nP</th>\n",
       "      <th>ground_truth_Tokens</th>\n",
       "      <th>ground_truth_nSW_Tokens</th>\n",
       "      <th>ground_truth_nSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aze_19130917_12_SEARCH_0</td>\n",
       "      <td>SEARCH</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>kutscher polizeilich geprüft bittet um posten ...</td>\n",
       "      <td>kutscher um bachgasse</td>\n",
       "      <td>kutscher polizeilich geprüft bittet um posten ...</td>\n",
       "      <td>[kutscher, polizeilich, geprüft, bittet, um, p...</td>\n",
       "      <td>[kutscher, polizeilich, geprüft, bittet, poste...</td>\n",
       "      <td>kutscher polizeilich geprüft bittet posten xvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aze_19130917_12_OFFER_1</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>einige jüngere lustergürter finden dauernde be...</td>\n",
       "      <td>einige jüngere uustgirter finden danernde besc...</td>\n",
       "      <td>einige jüngere lustergürter finden dauernde be...</td>\n",
       "      <td>[einige, jüngere, lustergürter, finden, dauern...</td>\n",
       "      <td>[jüngere, lustergürter, finden, dauernde, besc...</td>\n",
       "      <td>jüngere lustergürter finden dauernde beschäfti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aze_19130917_12_OFFER_2</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>lehrmädchen zum kleidermachen wird aufgenommen...</td>\n",
       "      <td>lehrmädchen äum kleidermachen wird aufgenommen...</td>\n",
       "      <td>lehrmädchen zum kleidermachen wird aufgenommen...</td>\n",
       "      <td>[lehrmädchen, zum, kleidermachen, wird, aufgen...</td>\n",
       "      <td>[lehrmädchen, kleidermachen, aufgenommen, lehr...</td>\n",
       "      <td>lehrmädchen kleidermachen aufgenommen lehrzeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aze_19130917_12_OFFER_3</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen und kettl...</td>\n",
       "      <td>schneid erinnen ausferti an und kettlerinnen w...</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen und kettl...</td>\n",
       "      <td>[schneiderinnen, 1111, ausfertigerinnen, und, ...</td>\n",
       "      <td>[schneiderinnen, 1111, ausfertigerinnen, kettl...</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen kettlerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aze_19130917_12_OFFER_4</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>[als, wäscherin, oder, bedienerin, sucht, eine...</td>\n",
       "      <td>[wäscherin, bedienerin, sucht, frau, posten, z...</td>\n",
       "      <td>wäscherin bedienerin sucht frau posten zuschri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 identifier region_class pub_id          pub_name  date  \\\n",
       "0  aze_19130917_12_SEARCH_0       SEARCH    aze  Arbeiter-Zeitung  1913   \n",
       "1   aze_19130917_12_OFFER_1        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "2   aze_19130917_12_OFFER_2        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "3   aze_19130917_12_OFFER_3        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "4   aze_19130917_12_OFFER_4        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "\n",
       "                             ground_truth_normalized  \\\n",
       "0  kutscher polizeilich geprüft bittet um posten ...   \n",
       "1  einige jüngere lustergürter finden dauernde be...   \n",
       "2  lehrmädchen zum kleidermachen wird aufgenommen...   \n",
       "3  schneiderinnen 1111 ausfertigerinnen und kettl...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                      OCR_normalized  \\\n",
       "0                             kutscher um bachgasse    \n",
       "1  einige jüngere uustgirter finden danernde besc...   \n",
       "2  lehrmädchen äum kleidermachen wird aufgenommen...   \n",
       "3  schneid erinnen ausferti an und kettlerinnen w...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                     ground_truth_nP  \\\n",
       "0  kutscher polizeilich geprüft bittet um posten ...   \n",
       "1  einige jüngere lustergürter finden dauernde be...   \n",
       "2  lehrmädchen zum kleidermachen wird aufgenommen...   \n",
       "3  schneiderinnen 1111 ausfertigerinnen und kettl...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                 ground_truth_Tokens  \\\n",
       "0  [kutscher, polizeilich, geprüft, bittet, um, p...   \n",
       "1  [einige, jüngere, lustergürter, finden, dauern...   \n",
       "2  [lehrmädchen, zum, kleidermachen, wird, aufgen...   \n",
       "3  [schneiderinnen, 1111, ausfertigerinnen, und, ...   \n",
       "4  [als, wäscherin, oder, bedienerin, sucht, eine...   \n",
       "\n",
       "                             ground_truth_nSW_Tokens  \\\n",
       "0  [kutscher, polizeilich, geprüft, bittet, poste...   \n",
       "1  [jüngere, lustergürter, finden, dauernde, besc...   \n",
       "2  [lehrmädchen, kleidermachen, aufgenommen, lehr...   \n",
       "3  [schneiderinnen, 1111, ausfertigerinnen, kettl...   \n",
       "4  [wäscherin, bedienerin, sucht, frau, posten, z...   \n",
       "\n",
       "                                    ground_truth_nSW  \n",
       "0  kutscher polizeilich geprüft bittet posten xvi...  \n",
       "1  jüngere lustergürter finden dauernde beschäfti...  \n",
       "2  lehrmädchen kleidermachen aufgenommen lehrzeit...  \n",
       "3  schneiderinnen 1111 ausfertigerinnen kettlerin...  \n",
       "4  wäscherin bedienerin sucht frau posten zuschri...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Wortzählungen für die Stopwort Liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xss = df['ground_truth_Tokens'].tolist()\n",
    "tokenOverview = [x for xs in xss for x in xs]\n",
    "df_tokenOverview = pd.DataFrame(tokenOverview, columns =['Wörter'])\n",
    "\n",
    "df_tokenOverview['Frequenz'] = df_tokenOverview.groupby('Wörter')['Wörter'].transform('count')\n",
    "df_tokenOverview = df_tokenOverview.drop_duplicates()\n",
    "df_tokenOverview = df_tokenOverview.sort_values(by=['Frequenz'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wörter</th>\n",
       "      <th>Frequenz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aufgenommen</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>und</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>werden</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>für</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>wird</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>in</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>sofort</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>der</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>an</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tür</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>gegen</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>bei</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gesucht</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>die</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tüchtige</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Wörter  Frequenz\n",
       "32   aufgenommen       655\n",
       "43           und       594\n",
       "45        werden       457\n",
       "97           für       412\n",
       "31          wird       335\n",
       "23            in       229\n",
       "279       sofort       208\n",
       "460          der       194\n",
       "20            an       186\n",
       "8            tür       185\n",
       "106        gegen       184\n",
       "260          bei       184\n",
       "76       gesucht       184\n",
       "21           die       179\n",
       "70      tüchtige       159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenOverview.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisierung aller Stopwords, die extrahiert wurden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_top_stopwords_barchart(df[columnname+\"_nP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Berechnung der Anzahl der Wörter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>region_class</th>\n",
       "      <th>pub_id</th>\n",
       "      <th>pub_name</th>\n",
       "      <th>date</th>\n",
       "      <th>ground_truth_normalized</th>\n",
       "      <th>OCR_normalized</th>\n",
       "      <th>ground_truth_nP</th>\n",
       "      <th>ground_truth_Tokens</th>\n",
       "      <th>ground_truth_nSW_Tokens</th>\n",
       "      <th>ground_truth_nSW</th>\n",
       "      <th>Num_Token_ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aze_19130917_12_SEARCH_0</td>\n",
       "      <td>SEARCH</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>kutscher polizeilich geprüft bittet um posten ...</td>\n",
       "      <td>kutscher um bachgasse</td>\n",
       "      <td>kutscher polizeilich geprüft bittet um posten ...</td>\n",
       "      <td>[kutscher, polizeilich, geprüft, bittet, um, p...</td>\n",
       "      <td>[kutscher, polizeilich, geprüft, bittet, poste...</td>\n",
       "      <td>kutscher polizeilich geprüft bittet posten xvi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aze_19130917_12_OFFER_1</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>einige jüngere lustergürter finden dauernde be...</td>\n",
       "      <td>einige jüngere uustgirter finden danernde besc...</td>\n",
       "      <td>einige jüngere lustergürter finden dauernde be...</td>\n",
       "      <td>[einige, jüngere, lustergürter, finden, dauern...</td>\n",
       "      <td>[jüngere, lustergürter, finden, dauernde, besc...</td>\n",
       "      <td>jüngere lustergürter finden dauernde beschäfti...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aze_19130917_12_OFFER_2</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>lehrmädchen zum kleidermachen wird aufgenommen...</td>\n",
       "      <td>lehrmädchen äum kleidermachen wird aufgenommen...</td>\n",
       "      <td>lehrmädchen zum kleidermachen wird aufgenommen...</td>\n",
       "      <td>[lehrmädchen, zum, kleidermachen, wird, aufgen...</td>\n",
       "      <td>[lehrmädchen, kleidermachen, aufgenommen, lehr...</td>\n",
       "      <td>lehrmädchen kleidermachen aufgenommen lehrzeit...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aze_19130917_12_OFFER_3</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen und kettl...</td>\n",
       "      <td>schneid erinnen ausferti an und kettlerinnen w...</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen und kettl...</td>\n",
       "      <td>[schneiderinnen, 1111, ausfertigerinnen, und, ...</td>\n",
       "      <td>[schneiderinnen, 1111, ausfertigerinnen, kettl...</td>\n",
       "      <td>schneiderinnen 1111 ausfertigerinnen kettlerin...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aze_19130917_12_OFFER_4</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>aze</td>\n",
       "      <td>Arbeiter-Zeitung</td>\n",
       "      <td>1913</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>als wäscherin oder bedienerin sucht eine frau ...</td>\n",
       "      <td>[als, wäscherin, oder, bedienerin, sucht, eine...</td>\n",
       "      <td>[wäscherin, bedienerin, sucht, frau, posten, z...</td>\n",
       "      <td>wäscherin bedienerin sucht frau posten zuschri...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 identifier region_class pub_id          pub_name  date  \\\n",
       "0  aze_19130917_12_SEARCH_0       SEARCH    aze  Arbeiter-Zeitung  1913   \n",
       "1   aze_19130917_12_OFFER_1        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "2   aze_19130917_12_OFFER_2        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "3   aze_19130917_12_OFFER_3        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "4   aze_19130917_12_OFFER_4        OFFER    aze  Arbeiter-Zeitung  1913   \n",
       "\n",
       "                             ground_truth_normalized  \\\n",
       "0  kutscher polizeilich geprüft bittet um posten ...   \n",
       "1  einige jüngere lustergürter finden dauernde be...   \n",
       "2  lehrmädchen zum kleidermachen wird aufgenommen...   \n",
       "3  schneiderinnen 1111 ausfertigerinnen und kettl...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                      OCR_normalized  \\\n",
       "0                             kutscher um bachgasse    \n",
       "1  einige jüngere uustgirter finden danernde besc...   \n",
       "2  lehrmädchen äum kleidermachen wird aufgenommen...   \n",
       "3  schneid erinnen ausferti an und kettlerinnen w...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                     ground_truth_nP  \\\n",
       "0  kutscher polizeilich geprüft bittet um posten ...   \n",
       "1  einige jüngere lustergürter finden dauernde be...   \n",
       "2  lehrmädchen zum kleidermachen wird aufgenommen...   \n",
       "3  schneiderinnen 1111 ausfertigerinnen und kettl...   \n",
       "4  als wäscherin oder bedienerin sucht eine frau ...   \n",
       "\n",
       "                                 ground_truth_Tokens  \\\n",
       "0  [kutscher, polizeilich, geprüft, bittet, um, p...   \n",
       "1  [einige, jüngere, lustergürter, finden, dauern...   \n",
       "2  [lehrmädchen, zum, kleidermachen, wird, aufgen...   \n",
       "3  [schneiderinnen, 1111, ausfertigerinnen, und, ...   \n",
       "4  [als, wäscherin, oder, bedienerin, sucht, eine...   \n",
       "\n",
       "                             ground_truth_nSW_Tokens  \\\n",
       "0  [kutscher, polizeilich, geprüft, bittet, poste...   \n",
       "1  [jüngere, lustergürter, finden, dauernde, besc...   \n",
       "2  [lehrmädchen, kleidermachen, aufgenommen, lehr...   \n",
       "3  [schneiderinnen, 1111, ausfertigerinnen, kettl...   \n",
       "4  [wäscherin, bedienerin, sucht, frau, posten, z...   \n",
       "\n",
       "                                    ground_truth_nSW  Num_Token_ground_truth  \n",
       "0  kutscher polizeilich geprüft bittet posten xvi...                      10  \n",
       "1  jüngere lustergürter finden dauernde beschäfti...                      18  \n",
       "2  lehrmädchen kleidermachen aufgenommen lehrzeit...                      12  \n",
       "3  schneiderinnen 1111 ausfertigerinnen kettlerin...                      14  \n",
       "4  wäscherin bedienerin sucht frau posten zuschri...                      16  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Tokens and save in new column\n",
    "df['Num_Token_ground_truth'] = df[\"ground_truth_Tokens\"].str.len()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all job ads without stopwords as txt file\n",
    "with open('../output/4.1_text_preparation_ground_truth/ground_truth_nSW.txt', 'w', encoding = 'utf-8') as f:\n",
    "    for rec_index, rec in df.iterrows():\n",
    "        f.write(rec['ground_truth_nSW'] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the prepared korpus\n",
    "df.to_csv(r\"../output/4.1_text_preparation_ground_truth/text_prep_ground_truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
